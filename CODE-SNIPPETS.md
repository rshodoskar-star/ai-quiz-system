# ğŸ’» Code Snippets â€“ AI Quiz System

ØªØ­ØªÙˆÙŠ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ù…Ù„ÙØ§Øª PDFØŒ ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„ÙƒØªÙ„ØŒ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ÙˆØ§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ØµÙˆØ±Ø© (OCR)ØŒ ÙˆØ°Ù„Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© **PyMuPDF** ÙˆÙ…ÙƒØªØ¨Ø§Øª Ø£Ø®Ø±Ù‰. ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙƒØ£Ø³Ø§Ø³ Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø£ÙÙƒØ§Ø± Ù…Ø­Ù„ÙŠØ§Ù‹.

## 1. Ù…Ù‚Ø§Ø±Ù†Ø© Ø£ÙˆØ¶Ø§Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ (`text` vs `dict`)

```python
import fitz  # PyMuPDF

# ÙØªØ­ Ù…Ù„Ù PDF
with fitz.open("example.pdf") as doc:
    page = doc[0]

    # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¨Ø³ÙŠØ·: text
    text_simple = page.get_text("text")
    print("Extracted using 'text':\n", text_simple[:500])

    # Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…: dict
    text_dict = page.get_text("dict")
    print("Keys in dict output:", text_dict.keys())
    # dict['blocks'] ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒØªÙ„ Ù…Ø¹ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§ØªÙ‡Ø§
```

## 2. ÙØ±Ø² Ø§Ù„ÙƒØªÙ„ ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ (RTL)

```python
from operator import itemgetter

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªÙ„ Ù…Ù† dict
blocks = text_dict.get("blocks", [])

# ÙØ±Ø² Ø§Ù„Ø¨Ù„ÙˆÙƒØ§Øª Ù…Ù† Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù„Ù„Ø£Ø³ÙÙ„ (y) Ø«Ù… Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø± (x Ø³Ø§Ù„Ø¨)
sorted_blocks = sorted(
    blocks, key=lambda b: (b["bbox"][1], -b["bbox"][0])
)

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙƒØªÙ„
lines = []
for block in sorted_blocks:
    if block.get("type") != 0:  # 0 ØªØ¹Ù†ÙŠ Ù†ØµØŒ 1 ØªØ¹Ù†ÙŠ ØµÙˆØ±Ø©
        continue
    for line in block.get("lines", []):
        # ØªØ±ØªÙŠØ¨ spans Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø±
        spans = sorted(line.get("spans", []), key=lambda s: -s["bbox"][0])
        line_text = "".join(span["text"] for span in spans)
        lines.append(line_text.strip())

full_text = "\n".join(lines)
print(full_text)
```

## 3. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ØµÙˆØ±Ø© ÙˆØªØ´ØºÙŠÙ„ OCR

```python
from paddleocr import PaddleOCR

ocr_engine = PaddleOCR(use_angle_cls=True, lang='ar')

# Ø¯Ø§Ù„Ø© Ù„Ø§ÙƒØªØ´Ø§Ù Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙØ­Ø© Ù…ØµÙˆØ±Ø©
def is_scanned_page(page, text):
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ±Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ ÙˆÙ‡Ù†Ø§Ùƒ ØµÙˆØ± ÙÙŠ Ø§Ù„ØµÙØ­Ø©
    return (len(text.strip()) < 80) and (len(page.get_images()) > 0)

for page_num in range(len(doc)):
    page = doc[page_num]
    raw_text = page.get_text("text")
    if is_scanned_page(page, raw_text):
        # ØªØ´ØºÙŠÙ„ OCR
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
        img_path = f"tmp_page{page_num}.png"
        pix.save(img_path)
        ocr_result = ocr_engine.ocr(img_path, cls=True)
        scanned_text = "\n".join([line[1][0] for line in ocr_result])
        print("OCR text:\n", scanned_text)
    else:
        print("Parsed text:\n", raw_text[:200])
```

## 4. ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„

```python
import re
import unicodedata
from ftfy import fix_text

def normalize_arabic_text(text: str) -> str:
    # Ø¥ØµÙ„Ø§Ø­ UTFâ€‘8 ØºÙŠØ± Ø§Ù„ØµØ­ÙŠØ­
    text = fix_text(text)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    text = re.sub(r'[\u064B-\u0652]', '', text)
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù„Ù
    text = re.sub(r'[Ø£Ø¥Ø¢]', 'Ø§', text)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

clean_text = normalize_arabic_text(full_text)
print(clean_text[:500])
```

## 5. Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„ (Ù…ÙÙ‡ÙˆÙ… Ù…Ø¨Ø³Ø·)

Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ù„Ø§Ø­Ø¸Ø© ØªØºÙŠØ± ÙƒØ¨ÙŠØ± ÙÙŠ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª `x` Ø¨ÙŠÙ† Ø§Ù„Ø¨Ù„ÙˆÙƒØ§ØªØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ Ø¬Ø¯ÙŠØ¯. ÙŠÙ…ÙƒÙ† ØªÙˆØ³ÙŠØ¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:

```python
columns = []
current_column = []
last_x = None

for block in sorted_blocks:
    x0 = block["bbox"][0]
    if last_x is not None and abs(x0 - last_x) > 200:  # Ø¹ØªØ¨Ø© Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        columns.append(current_column)
        current_column = []
    current_column.append(block)
    last_x = x0

if current_column:
    columns.append(current_column)

print(f"Detected {len(columns)} columns")
```

## 6. Ù…Ø«Ø§Ù„ ÙƒØ§Ù…Ù„ Ù„Ù„Ù€ Pipeline

```python
def extract_full_text(pdf_path: str) -> str:
    """ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† parsing Ùˆ OCR ÙˆØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ."""
    doc = fitz.open(pdf_path)
    all_pages_text = []

    for page in doc:
        # Ø§Ù„ÙˆØ¶Ø¹ dict Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ®Ø·ÙŠØ·
        pdict = page.get_text("dict")
        blocks = sorted(
            pdict.get("blocks", []), key=lambda b: (b["bbox"][1], -b["bbox"][0])
        )
        page_lines = []
        for block in blocks:
            if block.get("type") != 0:
                continue
            for line in block.get("lines", []):
                spans = sorted(line.get("spans", []), key=lambda s: -s["bbox"][0])
                text_line = "".join(span["text"] for span in spans).strip()
                page_lines.append(text_line)
        page_text = "\n".join(page_lines)

        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ù‚ØµÙŠØ±Ø§Ù‹ Ø§Ø³ØªØ®Ø¯Ù… OCR
        if is_scanned_page(page, page_text):
            pix = page.get_pixmap(matrix=fitz.Matrix(2,2))
            tmp = "tmp.png"
            pix.save(tmp)
            ocr_text = ocr_engine.ocr(tmp, cls=True)
            page_text = "\n".join([x[1][0] for x in ocr_text])
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ
        page_text = normalize_arabic_text(page_text)
        all_pages_text.append(page_text)

    return "\n\n".join(all_pages_text)
```

Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙƒØ£Ø³Ø§Ø³ Ù„ØªØ¬Ø±Ø¨Ø© ØªÙ‚Ù†ÙŠØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙˆØªØ±ØªÙŠØ¨Ù‡Ø§ØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ù…Ù† Ù…Ù„ÙØ§Øª PDF.
